{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d48999d6-4939-472e-a0fc-743ebb2b28ed",
   "metadata": {},
   "source": [
    "# 딥러닝을 이용한 수능 영어 풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5491b5e9-2eb1-48f1-8414-4e1d3f7cd00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ysher/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchtext.legacy.data import Field\n",
    "from torchtext.legacy.data import TabularDataset\n",
    "from torchtext.legacy.data import BucketIterator, Iterator\n",
    "\n",
    "RANDOM_SEED = 2020\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "DATA_PATH = \"../data/processed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bb1b2b-b267-4e74-bc28-38440363b87c",
   "metadata": {},
   "source": [
    "### 모델 클래스 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "079f30e8-9bdc-492a-9b0d-4748e2ea489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size, num_layers, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embed_layer = nn.Embedding(\n",
    "            num_embeddings=num_embeddings,embedding_dim=embedding_dim,padding_idx=pad_idx)\n",
    "        self.lstm_layer = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            dropout=0.5\n",
    "        )\n",
    "        self.last_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size*2, hidden_size),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        embed_x = self.embed_layer(x)\n",
    "        output, (_,_) = self.lstm_layer(embed_x)\n",
    "        last_output = output[:,-1,:]\n",
    "        last_output = self.last_layer(last_output)\n",
    "        return last_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a110140d-4775-4699-bac9-457e5b9004c6",
   "metadata": {},
   "source": [
    "## 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c28f9000-0f4c-4650-a0ac-caf302523f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(\n",
    "    sequential=True, # 문장이 들어온다\n",
    "    use_vocab=True, # 따로 단어장을 만드는가?\n",
    "    tokenize=word_tokenize, \n",
    "    lower=True,\n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "LABEL = Field(\n",
    "    sequential=False,\n",
    "    use_vocab=False,\n",
    "    batch_first=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98889e09-ad71-4cdc-b678-b54fa134d93f",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9249660-8a4c-4300-8cb5-002c291a108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_train_data, sat_valid_data, sat_test_data = TabularDataset.splits(\n",
    "                                                    path = \"../data/\",\n",
    "                                                    train = \"sat_train.tsv\",\n",
    "                                                    validation = \"sat_valid.tsv\",\n",
    "                                                    test = \"sat_test.tsv\",\n",
    "                                                    format = \"tsv\",\n",
    "                                                    fields = [(\"text\",TEXT),(\"label\",LABEL)],\n",
    "                                                    skip_header = 1,\n",
    "                                                )\n",
    "TEXT.build_vocab(sat_train_data, min_freq=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a5b20-7a10-4436-b13f-3cbca3bcde40",
   "metadata": {},
   "source": [
    "### Data Loader 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0175da85-c3f0-4771-9525-de01ae68b271",
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_train_iterator, sat_valid_iterator, sat_test_iterator = BucketIterator.splits(\n",
    "    (sat_train_data, sat_valid_data, sat_test_data),\n",
    "    batch_size=8,\n",
    "    device=None,\n",
    "    sort=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5faad33-a44d-4a0e-8a6e-48e1d06d3e12",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b08c064-ad7f-4bbc-be4c-6c9b43f69b3a",
   "metadata": {},
   "source": [
    "### 모델 학습 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c20c54a-0af7-4062-9299-7b00cf869007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        text = batch.text\n",
    "        if text.shape[0] >1 :\n",
    "            label = batch.label.type(torch.FloatTensor)\n",
    "            text = text.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(text).flatten()\n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss/len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143882d8-d888-473d-b630-4052f1c34f15",
   "metadata": {},
   "source": [
    "### 모델 평가 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7266654b-1c57-4fb7-9a33-2316b2d25f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, valid_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(valid_loader):\n",
    "            text = batch.text\n",
    "            label = batch.label.type(torch.FloatTensor)\n",
    "            text = text.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(text).flatten()\n",
    "            loss = criterion(output, label)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss/len(valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7e9cf9-a6a9-4150-ac98-660631b67fed",
   "metadata": {},
   "source": [
    "### HyperParameter 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4f8397f-388b-4b27-b11a-ac1cff066d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "N_EPOCHS = 20\n",
    "\n",
    "lstm_classifier = LSTMClassifier(num_embeddings=len(TEXT.vocab),\n",
    "                                embedding_dim=100,\n",
    "                                hidden_size=200,\n",
    "                                num_layers=4,\n",
    "                                pad_idx=PAD_IDX)\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "_ = lstm_classifier.to(device)\n",
    "optimizer = torch.optim.Adam(lstm_classifier.parameters())\n",
    "bce_loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb83b5-3a33-470a-9b1c-20b3a05b3494",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed6dceeb-db1e-4cd9-a18d-d994575274ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 0.52060\n",
      "\tVal. Loss: 0.76532\n",
      "Epoch: 02\n",
      "\tTrain Loss: 0.51065\n",
      "\tVal. Loss: 0.55898\n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.47559\n",
      "\tVal. Loss: 0.54429\n",
      "Epoch: 04\n",
      "\tTrain Loss: 0.43671\n",
      "\tVal. Loss: 0.53830\n",
      "Epoch: 05\n",
      "\tTrain Loss: 0.42772\n",
      "\tVal. Loss: 0.53806\n",
      "Epoch: 06\n",
      "\tTrain Loss: 0.40104\n",
      "\tVal. Loss: 0.54618\n",
      "Epoch: 07\n",
      "\tTrain Loss: 0.43988\n",
      "\tVal. Loss: 0.53907\n",
      "Epoch: 08\n",
      "\tTrain Loss: 0.42333\n",
      "\tVal. Loss: 0.53079\n",
      "Epoch: 09\n",
      "\tTrain Loss: 0.42076\n",
      "\tVal. Loss: 0.53789\n",
      "Epoch: 10\n",
      "\tTrain Loss: 0.43361\n",
      "\tVal. Loss: 0.53598\n",
      "Epoch: 11\n",
      "\tTrain Loss: 0.43992\n",
      "\tVal. Loss: 0.53834\n",
      "Epoch: 12\n",
      "\tTrain Loss: 0.46740\n",
      "\tVal. Loss: 0.53208\n",
      "Epoch: 13\n",
      "\tTrain Loss: 0.42639\n",
      "\tVal. Loss: 0.54740\n",
      "Epoch: 14\n",
      "\tTrain Loss: 0.42282\n",
      "\tVal. Loss: 0.58034\n",
      "Epoch: 15\n",
      "\tTrain Loss: 0.41925\n",
      "\tVal. Loss: 0.57024\n",
      "Epoch: 16\n",
      "\tTrain Loss: 0.42093\n",
      "\tVal. Loss: 0.55255\n",
      "Epoch: 17\n",
      "\tTrain Loss: 0.43579\n",
      "\tVal. Loss: 0.55127\n",
      "Epoch: 18\n",
      "\tTrain Loss: 0.43980\n",
      "\tVal. Loss: 0.56086\n",
      "Epoch: 19\n",
      "\tTrain Loss: 0.43909\n",
      "\tVal. Loss: 0.54740\n",
      "Epoch: 20\n",
      "\tTrain Loss: 0.42460\n",
      "\tVal. Loss: 0.56479\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(\n",
    "        lstm_classifier,\n",
    "        sat_train_iterator,\n",
    "        optimizer,\n",
    "        bce_loss_fn,\n",
    "        device\n",
    "    )\n",
    "    valid_loss = evaluate(\n",
    "        lstm_classifier,\n",
    "        sat_valid_iterator,\n",
    "        bce_loss_fn,\n",
    "        device\n",
    "    )\n",
    "    print(f\"Epoch: {epoch+1:02}\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.5f}\")\n",
    "    print(f\"\\tVal. Loss: {valid_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb455f9-fb9c-4e12-95a7-30817de7982b",
   "metadata": {},
   "source": [
    "### 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22dd1177-da53-48a0-9c30-3272314e1ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"baseline_model.dill\", \"wb\") as f:\n",
    "    model = {\n",
    "        \"TEXT\": TEXT,\n",
    "        \"LABEL\": LABEL,\n",
    "        \"classifier\": lstm_classifier\n",
    "    }\n",
    "    dill.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c306d06-f206-48dd-859e-54096b8cf53d",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349e1bd6-4755-4e79-9c3f-684cc2292ef4",
   "metadata": {},
   "source": [
    "### 테스트 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "414c4f7d-5b1b-4c38-8ff0-b13d68793f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_real = []\n",
    "        y_pred = []\n",
    "        \n",
    "        for batch in test_loader:\n",
    "            text = batch.text\n",
    "            label = batch.label.type(torch.FloatTensor)\n",
    "            text = text.to(device)\n",
    "            \n",
    "            output = model(text).flatten().cpu()\n",
    "            \n",
    "            y_real += [label]\n",
    "            y_pred += [output]\n",
    "        \n",
    "        y_real = torch.cat(y_real)\n",
    "        y_pred = torch.cat(y_pred)\n",
    "        \n",
    "    fpr, tpr, _ = roc_curve(y_real, y_pred)\n",
    "    auroc = auc(fpr, tpr)\n",
    "    \n",
    "    return auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f88dd4-bc3f-483b-b79b-910a351b35a3",
   "metadata": {},
   "source": [
    "### 모델 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfe73709-d280-4c51-990f-c3648386aa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAT Dateset Test AUROC: 0.84615\n"
     ]
    }
   ],
   "source": [
    "_ = lstm_classifier.cpu()\n",
    "test_auroc = test(\n",
    "    lstm_classifier,\n",
    "    sat_test_iterator,\n",
    "    \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"SAT Dateset Test AUROC: {test_auroc:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cad0f3-4c12-4671-8a97-3cf202ac1814",
   "metadata": {},
   "source": [
    "## 성능 높이기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a52fc4a-f6d4-418d-bb1f-baec46e05c04",
   "metadata": {},
   "source": [
    "### 추가 데이터 이용\n",
    "\n",
    "- pre trained model을 만들어 사용\n",
    "\n",
    "- train 데이터에 넣지 않고 사전 훈련 하는 이유 : train에 넣고 같이 진행할 경우 데이터가 큰 추가데이터에 오버피팅 될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0d1eee-33de-45f5-9303-10113cbceb81",
   "metadata": {},
   "source": [
    "### 추가 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d358399-96ba-4481-836d-0d0bf515613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(\n",
    "    sequential=True, # 문장이 들어온다\n",
    "    use_vocab=True, # 따로 단어장을 만드는가?\n",
    "    tokenize=word_tokenize, \n",
    "    lower=True,\n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "LABEL = Field(\n",
    "    sequential=False,\n",
    "    use_vocab=False,\n",
    "    batch_first=True\n",
    ")\n",
    "cola_train_data, cola_valid_data, cola_test_data = TabularDataset.splits(\n",
    "                                                    path = \"../data/\",\n",
    "                                                    train = \"cola_train.tsv\",\n",
    "                                                    validation = \"cola_valid.tsv\",\n",
    "                                                    test = \"cola_test.tsv\",\n",
    "                                                    format = \"tsv\",\n",
    "                                                    fields = [(\"text\",TEXT),(\"label\",LABEL)],\n",
    "                                                    skip_header = 1,\n",
    "                                                )\n",
    "TEXT.build_vocab(cola_train_data, min_freq=2)\n",
    "\n",
    "cola_train_iterator, cola_valid_iterator, cola_test_iterator = BucketIterator.splits(\n",
    "    (cola_train_data, cola_valid_data, cola_test_data),\n",
    "    batch_size=32,\n",
    "    device=None,\n",
    "    sort=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8550a343-ecc0-40c8-9b72-f5eeddf6b5f4",
   "metadata": {},
   "source": [
    "### 기존 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2fb10d7-6f60-4d1c-959b-b9ced2528683",
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_train_data, sat_valid_data, sat_test_data = TabularDataset.splits(\n",
    "                                                    path = \"../data/\",\n",
    "                                                    train = \"sat_train.tsv\",\n",
    "                                                    validation = \"sat_valid.tsv\",\n",
    "                                                    test = \"sat_test.tsv\",\n",
    "                                                    format = \"tsv\",\n",
    "                                                    fields = [(\"text\",TEXT),(\"label\",LABEL)],\n",
    "                                                    skip_header = 1,\n",
    "                                                )\n",
    "\n",
    "sat_train_iterator, sat_valid_iterator, sat_test_iterator = BucketIterator.splits(\n",
    "    (sat_train_data, sat_valid_data, sat_test_data),\n",
    "    batch_size=8,\n",
    "    device=None,\n",
    "    sort=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203660e2-e92f-4a84-be62-85a95dbe7392",
   "metadata": {},
   "source": [
    "### 모델 사전 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23e40d86-3615-4bbe-9fd6-6bf1073be3c2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 0.61577\n",
      "\tVal. Loss: 0.56479\n",
      "Epoch: 02\n",
      "\tTrain Loss: 0.61246\n",
      "\tVal. Loss: 0.56479\n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.61109\n",
      "\tVal. Loss: 0.56479\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5837b3959b98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m                        \u001b[0mcola_valid_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                        \u001b[0mbce_loss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                        device)\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch: {epoch+1:02}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-566a3c458b17>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, valid_loader, criterion, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ysher_yonsei/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-40207424be89>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0membed_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mlast_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mlast_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ysher_yonsei/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ysher_yonsei/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 692\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "N_EPOCHS = 20\n",
    "\n",
    "lstm_classifier = LSTMClassifier(\n",
    "    num_embeddings=len(TEXT.vocab),\n",
    "    embedding_dim=100,\n",
    "    hidden_size=200,\n",
    "    num_layers=4,\n",
    "    pad_idx=PAD_IDX,\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "_ = lstm_classifier.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm_classifier.parameters())\n",
    "bce_loss_fn = nn.BCELoss()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(lstm_classifier,\n",
    "                      cola_train_iterator,\n",
    "                      optimizer,\n",
    "                      bce_loss_fn,\n",
    "                      device)\n",
    "    \n",
    "    val_loss = evaluate(lstm_classifier,\n",
    "                       cola_valid_iterator,\n",
    "                       bce_loss_fn,\n",
    "                       device)\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1:02}\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.5f}\")\n",
    "    print(f\"\\tVal. Loss: {valid_loss:.5f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b548ccb-cd95-437b-8986-e1c2d7daa3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "before_tuning_lstm_classifier = deepcopy(lstm_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54965cb6-b060-43fa-8fd6-a9c39eb49ed0",
   "metadata": {},
   "source": [
    "### 모델 추가 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37721a0-e7d0-45a5-9c18-ec80f3c4fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "N_EPOCHS = 20\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(\n",
    "        lstm_classifier,\n",
    "        sat_train_iterator,\n",
    "        optimizer,\n",
    "        bce_loss_fn,\n",
    "        device\n",
    "    )\n",
    "    valid_loss = evaluate(\n",
    "        lstm_classifier,\n",
    "        sat_valid_iterator,\n",
    "        bce_loss_fn,\n",
    "        device\n",
    "    )\n",
    "    print(f\"Epoch: {epoch+1:02}\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.5f}\")\n",
    "    print(f\"\\tVal. Loss: {valid_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a018aa6-e8cb-4414-8915-6814a4ff5de8",
   "metadata": {},
   "source": [
    "### 모델 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a06d7fa-fb18-4bb6-bfd5-c65fa59feafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = before_tuning_lstm_classifier.cpu()\n",
    "lstm_sat_test_auroc = test(before_tuning_lstm_classifier, sat_test_iterator,\"cpu\")\n",
    "_ = lstm_classifier.cpu()\n",
    "lstm_tuned_test_auroc = test(lstm_classifier, sat_test_iterator, \"cpu\")\n",
    "\n",
    "print(f\"Before fine-tuning SAT Dataset Test AUROC: {lstm_sat_test_auroc:.5f}\")\n",
    "print(f\"After fine-tuning SAT Dataset Test AUROC: {lstm_tuned_test_auroc:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ac6010-7aa7-44b9-8719-c4e28d5fb17d",
   "metadata": {},
   "source": [
    "### 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88851121-199f-40a2-940d-4ec7c81a5130",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"before_tuning_model.dill\",\"wb\") as f:\n",
    "    model = {\n",
    "        \"TEXT\": TEXT,\n",
    "        \"LABEL\": LABEL,\n",
    "        \"classifier\": before_tuning_lstm_classifier\n",
    "    }\n",
    "    dill.dump(model, f)\n",
    "    \n",
    "_ = lstm_classifier.cpu()\n",
    "with open(\"after_tuning_model.dill\",\"wb\") as f:\n",
    "    model = {\n",
    "        \"TEXT\": TEXT,\n",
    "        \"LABEL\": LABEL,\n",
    "        \"classifier\": lstm_classifier\n",
    "    }\n",
    "    dill.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94bcb9f-c654-47b9-9fdb-e4e9dbacef90",
   "metadata": {},
   "source": [
    "## 심화 모델\n",
    "\n",
    "- LSTM의 전체 값을 max pooling 하여 사용한다. (문장길이, pading 문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6605ea6f-a8f3-426a-b49f-99738306fcf8",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb177e4d-ed80-4508-abe7-d1c306705f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMPoolingClassifier(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size, num_layers, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embed_layer = nn.Embedding(num_embeddings=num_embeddings,\n",
    "                                           embedding_dim=embedding_dim,\n",
    "                                           padding_idx=pad_idx)\n",
    "        \n",
    "        self.lstm_layer = nn.LSTM(input_size=embedding_dim,\n",
    "                                 hidden_size=hidden_size,\n",
    "                                 num_layers=num_layers,\n",
    "                                 bidirectional=True,\n",
    "                                 dropout=0.5,\n",
    "                                 batch_first=True)\n",
    "        \n",
    "        self.last_layer = nn.Sequential(nn.Linear(2*hidden_size,1),\n",
    "                                       nn.Dropout(p=0.5),\n",
    "                                       nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed_layer(x)\n",
    "        output, _ = self.lstm_layer(x)\n",
    "        pool = nn.functional.max_pool1d(output.transpose(1,2),x.shape[1])\n",
    "        pool = pool.transpose(1,2).squeeze()\n",
    "        output = self.last_layer(pool)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138f93f1-092d-463a-9d1c-31bca12cb00e",
   "metadata": {},
   "source": [
    "## 모델 사전 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8058b846-1274-46ca-bb12-a96584a7cc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 0.65498\n",
      "\tVal. Loss: 0.85817\n",
      "Epoch: 02\n",
      "\tTrain Loss: 0.64562\n",
      "\tVal. Loss: 0.85817\n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.63974\n",
      "\tVal. Loss: 0.85817\n",
      "Epoch: 04\n",
      "\tTrain Loss: 0.62967\n",
      "\tVal. Loss: 0.85817\n",
      "Epoch: 05\n",
      "\tTrain Loss: 0.61860\n",
      "\tVal. Loss: 0.85817\n",
      "Epoch: 06\n",
      "\tTrain Loss: 0.63392\n",
      "\tVal. Loss: 0.85817\n",
      "Epoch: 07\n",
      "\tTrain Loss: 0.63499\n",
      "\tVal. Loss: 0.85817\n",
      "Epoch: 08\n",
      "\tTrain Loss: 0.61458\n",
      "\tVal. Loss: 0.85817\n",
      "Epoch: 09\n",
      "\tTrain Loss: 0.59801\n",
      "\tVal. Loss: 0.85817\n",
      "Epoch: 10\n",
      "\tTrain Loss: 0.58919\n",
      "\tVal. Loss: 0.85817\n",
      "Epoch: 11\n",
      "\tTrain Loss: 0.56972\n",
      "\tVal. Loss: 0.85817\n",
      "Epoch: 12\n",
      "\tTrain Loss: 0.56575\n",
      "\tVal. Loss: 0.85817\n",
      "Epoch: 13\n",
      "\tTrain Loss: 0.55819\n",
      "\tVal. Loss: 0.85817\n",
      "Epoch: 14\n",
      "\tTrain Loss: 0.53673\n",
      "\tVal. Loss: 0.85817\n",
      "Epoch: 15\n",
      "\tTrain Loss: 0.52101\n",
      "\tVal. Loss: 0.85817\n",
      "Epoch: 16\n",
      "\tTrain Loss: 0.50902\n",
      "\tVal. Loss: 0.85817\n",
      "Epoch: 17\n",
      "\tTrain Loss: 0.50033\n",
      "\tVal. Loss: 0.85817\n",
      "Epoch: 18\n",
      "\tTrain Loss: 0.48945\n",
      "\tVal. Loss: 0.85817\n",
      "Epoch: 19\n",
      "\tTrain Loss: 0.48062\n",
      "\tVal. Loss: 0.85817\n",
      "Epoch: 20\n",
      "\tTrain Loss: 0.46766\n",
      "\tVal. Loss: 0.85817\n"
     ]
    }
   ],
   "source": [
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "N_EPOCHS = 20\n",
    "\n",
    "lstm_pool_classifier = LSTMPoolingClassifier(\n",
    "    num_embeddings=len(TEXT.vocab),\n",
    "    embedding_dim=100,\n",
    "    hidden_size=200,\n",
    "    num_layers=4,\n",
    "    pad_idx=PAD_IDX,\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "_ = lstm_pool_classifier.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm_pool_classifier.parameters())\n",
    "bce_loss_fn = nn.BCELoss()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(lstm_pool_classifier,\n",
    "                      cola_train_iterator,\n",
    "                      optimizer,\n",
    "                      bce_loss_fn,\n",
    "                      device)\n",
    "    \n",
    "    val_loss = evaluate(lstm_pool_classifier,\n",
    "                       cola_valid_iterator,\n",
    "                       bce_loss_fn,\n",
    "                       device)\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1:02}\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.5f}\")\n",
    "    print(f\"\\tVal. Loss: {valid_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fda0461-f023-4a3d-bed8-a765c1590952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "before_tuning_lstm_pool_classifier = deepcopy(lstm_pool_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0e2eca-096c-45f5-abae-3c31d78700ca",
   "metadata": {},
   "source": [
    "### 모델 추가학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f5af51b-3b5e-4a58-bc7c-5ae810908bdd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-5fddf8954606>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                       \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                       \u001b[0mbce_loss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                       device)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     valid_loss = evaluate(lstm_pool_classifier,\n",
      "\u001b[0;32m<ipython-input-6-24d216c7032b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ysher_yonsei/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-560908fa012e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ysher_yonsei/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ysher_yonsei/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ysher_yonsei/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper__index_select)"
     ]
    }
   ],
   "source": [
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "N_EPOCHS = 15\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(lstm_pool_classifier,\n",
    "                      sat_train_iterator,\n",
    "                      optimizer,\n",
    "                      bce_loss_fn,\n",
    "                      device)\n",
    "    \n",
    "    valid_loss = evaluate(lstm_pool_classifier,\n",
    "                         sat_valid_iterator,\n",
    "                         bce_loss_fn,\n",
    "                         device)\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1:02}\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.5f}\")\n",
    "    print(f\"\\tVal. Loss: {valid_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03339b3-2703-4d17-a141-96b05b8bae47",
   "metadata": {},
   "source": [
    "### 성능비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8dadf5fb-f63e-42f0-8f3f-4478fa8e788d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before fine-tuning SAT Dataset Test AUROC: 0.53846\n",
      "After fine-tuning SAT Dataset Test AUROC: 0.80769\n"
     ]
    }
   ],
   "source": [
    "_ = before_tuning_lstm_pool_classifier.cpu()\n",
    "_ = lstm_pool_classifier.cpu()\n",
    "\n",
    "pool_sat_test_auroc = test(before_tuning_lstm_pool_classifier, sat_test_iterator, \"cpu\")\n",
    "pool_tuned_test_auroc = test(lstm_pool_classifier, sat_test_iterator, \"cpu\")\n",
    "\n",
    "print(f\"Before fine-tuning SAT Dataset Test AUROC: {pool_sat_test_auroc:.5f}\")\n",
    "print(f\"After fine-tuning SAT Dataset Test AUROC: {pool_tuned_test_auroc:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec0ed0d-e579-4f15-85b9-a2cf46ad0702",
   "metadata": {},
   "source": [
    "### 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8c340c18-d7a9-45af-a850-1e862d448908",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../model/advanced_before_tuning_model.dill\", \"wb\") as f:\n",
    "    model = {\"TEXT\" : TEXT,\n",
    "            \"LABEL\" : LABEL,\n",
    "            \"classifier\" : before_tuning_lstm_pool_classifier}\n",
    "    dill.dump(model, f)\n",
    "\n",
    "with open(\"../model/advanced_after_tuning_model.dill\", \"wb\") as f:\n",
    "    model = {\"TEXT\" : TEXT,\n",
    "            \"LABEL\" : LABEL,\n",
    "            \"classifier\" : lstm_pool_classifier}\n",
    "    dill.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a80983-1d29-4a9f-bf4e-06fe55bed07d",
   "metadata": {},
   "source": [
    "## 데모"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac213f34-09a3-44ff-88e8-284cc3ce4cdc",
   "metadata": {},
   "source": [
    "### 성능비교 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "967611ad-94df-4895-9bc9-e3479d24a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model_path):\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = dill.load(f)\n",
    "        \n",
    "    sat_test_data = TabularDataset(path=f\"{DATA_PATH}sat_test.tsv\",\n",
    "                                  format = \"tsv\",\n",
    "                                  fields=[(\"text\", model[\"TEXT\"]),\n",
    "                                         (\"label\", model[\"LABEL\"])],\n",
    "                                  skip_header=1)\n",
    "    \n",
    "    sat_test_iterator = BucketIterator(sat_test_data,\n",
    "                                      batch_size=8,\n",
    "                                      device=None,\n",
    "                                      sort=False,\n",
    "                                      shuffle=False)\n",
    "    \n",
    "    classifier = model[\"classifier\"].cpu()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_real = []\n",
    "        y_pred = []\n",
    "        classifier.eval()\n",
    "        for batch in sat_test_iterator:\n",
    "            text = batch.text\n",
    "            label = batch.label.type(torch.FloatTensor)\n",
    "            \n",
    "            output = classifier(text).flatten().cpu()\n",
    "            \n",
    "            y_real += [label]\n",
    "            y_pred += [output]\n",
    "            \n",
    "        y_real = torch.cat(y_real)\n",
    "        y_pred = torch.cat(y_pred)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_real, y_pred)\n",
    "    auroc = auc(fpr, tpr)\n",
    "    \n",
    "    return auroc.round(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b3606-a683-4bc4-9502-ef03130d7e2e",
   "metadata": {},
   "source": [
    "### 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "be2c9e43-f469-453a-8314-1098f49ce07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 - baseline_model                 - Test AUROC: 0.84615\n",
      "Rank 2 - advanced_after_tuning_model    - Test AUROC: 0.80769\n",
      "Rank 3 - advanced_before_tuning_model   - Test AUROC: 0.53846\n",
      "Rank 4 - after_tuning_model             - Test AUROC: 0.46154\n",
      "Rank 5 - before_tuning_model            - Test AUROC: 0.38462\n"
     ]
    }
   ],
   "source": [
    "model_list = [\"baseline_model.dill\",\n",
    "             \"before_tuning_model.dill\",\n",
    "             \"after_tuning_model.dill\",\n",
    "             \"advanced_before_tuning_model.dill\",\n",
    "             \"advanced_after_tuning_model.dill\"]\n",
    "\n",
    "test_auroc = []\n",
    "for file_name in model_list:\n",
    "    model_name = file_name.replace(\".dill\",\"\")\n",
    "    auroc = test(\"../model/\" + file_name)\n",
    "    test_auroc += [(model_name,auroc)]\n",
    "    \n",
    "test_auroc = sorted(test_auroc, key=lambda x:x[1], reverse=True)\n",
    "for rank, (model_name, auroc) in enumerate(test_auroc):\n",
    "    print(f\"Rank {rank+1} - {model_name:30} - Test AUROC: {auroc:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ysher_yonsei",
   "language": "python",
   "name": "ysher_yonsei"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
